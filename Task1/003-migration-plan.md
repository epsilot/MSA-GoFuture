# План миграции данных

- С учётом большого объёма данных синхронное выполнение миграции невозможно, так как повлечёт за собой
  непримемлемый даунтайм.
- В качестве основного решения предлагается использовать брокер сообщений в комбинации с ACL для выполнения миграции
  даннных. По своей сути Event Sourcing, однако для поддержания консистентности изменений помимо событий об изменениях
  предлагает публиковать старые записи из БД монолита. Это позволит упорядочить процесс изменений.
- При этом на время миграции имеет смысл предусмотреть сохранение промежуточной информации о записях, которые были
  смигрированы (а точнее, что для них было отправлено событие с актуальным стейтом в kafka). Это позволит избежать
  ситуации при которой в ACL будет отправлено событие с изменениями записи, которой ещё нет в новой системе.
- Также такой подход позволит динамически управлять скоростью миграции. Размер порции синхронизируемыех записей можно
  будет увеличивать в часы с наименьшей нагрузкой или уменьшать (потенциально до нуля) - в часы пиковой нагрузки.
- В случае уменьшения порции синхронизируемых данных до нуля, на синхронизацию будут отправлять только записи, для
  которых выполняются изменения в текущий момент, что не видится большой проблемой.